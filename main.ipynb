{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "import time\n",
    "import pathlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from model.decoder import Decoder\n",
    "from model.encoder import CNN_Encoder\n",
    "from model.attention import BahdanauAttention\n",
    "from model.decoder import embedding_initializer\n",
    "from components.positional import add_timing_signal_nd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(\"data/small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = list(data_dir.glob(\"*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_paths = []\n",
    "for img in imgs:\n",
    "    imgs_paths.append(os.fspath(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_paths = sorted(set(imgs_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open(\"data/small.formulas.norm.txt\", 'r').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lines)):\n",
    "    lines[i] = \"<start> \" + lines[i] + \" <end>\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 400\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=top_k, oov_token=\"<unk>\", filters='')\n",
    "tokenizer.fit_on_texts(lines)\n",
    "train_seqs = tokenizer.texts_to_sequences(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index['<pad>'] = 0\n",
    "tokenizer.index_word[0] = '<pad>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_vector = tf.keras.preprocessing.sequence.pad_sequences(train_seqs, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = calc_max_length(train_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 80\n",
    "BATCH_SIZE = 2\n",
    "units = 512\n",
    "vocab_size = top_k + 1\n",
    "attention_features_shape = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path, formula):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_png(img)\n",
    "    return img, formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_only(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = img / 255\n",
    "    return img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation sets using an 80-20 split\n",
    "img_name_train, img_name_val, cap_train, cap_val = train_test_split(imgs_paths,\n",
    "                                                                    cap_vector,\n",
    "                                                                    test_size=0.2,\n",
    "                                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((img_name_train, cap_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(1000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = len(img_name_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Encoder Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CNN_Encoder(embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(embedding_dim, 512, vocab_size=top_k+1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(img, target):\n",
    "    loss = 0\n",
    "    img = img / 255\n",
    "    hidden = decoder.reset_state(batch_size=target.shape[0])\n",
    "    \n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * target.shape[0], 1)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        features = encoder(img)\n",
    "        \n",
    "        for i in range(1, target.shape[1]):\n",
    "            predictions, hidden, _ = decoder(dec_input, features, hidden)\n",
    "            \n",
    "            loss += loss_function(target[:, i], predictions)\n",
    "            \n",
    "            dec_input = tf.expand_dims(target[:, i], 1)\n",
    "            \n",
    "        total_loss = (loss / int(target.shape[1]))\n",
    "        \n",
    "        trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "        \n",
    "        gradients = tape.gradient(loss, trainable_variables)\n",
    "        \n",
    "        optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "        \n",
    "        return loss, total_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "ckpt = tf.train.Checkpoint(encoder=encoder, decoder=decoder, optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    start_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])\n",
    "    # restore to latest cehckpoint\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Batch 0 Loss 3.2732\n",
      "Epoch 8 Loss 1.450055\n",
      "Time taken for 1 epoch 5.271727085113525 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.7428\n",
      "Epoch 9 Loss 1.102265\n",
      "Time taken for 1 epoch 0.23688101768493652 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.8506\n",
      "Epoch 10 Loss 0.942810\n",
      "Time taken for 1 epoch 0.23837709426879883 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 2.0640\n",
      "Epoch 11 Loss 0.929335\n",
      "Time taken for 1 epoch 0.5234150886535645 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 1.7022\n",
      "Epoch 12 Loss 0.899456\n",
      "Time taken for 1 epoch 0.24530792236328125 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 1.5716\n",
      "Epoch 13 Loss 0.815287\n",
      "Time taken for 1 epoch 0.23948907852172852 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 1.5974\n",
      "Epoch 14 Loss 0.830973\n",
      "Time taken for 1 epoch 0.24467992782592773 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 2.1093\n",
      "Epoch 15 Loss 0.763219\n",
      "Time taken for 1 epoch 0.2456192970275879 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.9523\n",
      "Epoch 16 Loss 0.763099\n",
      "Time taken for 1 epoch 0.5381748676300049 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 1.4159\n",
      "Epoch 17 Loss 0.753880\n",
      "Time taken for 1 epoch 0.2521212100982666 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 1.6041\n",
      "Epoch 18 Loss 0.793468\n",
      "Time taken for 1 epoch 0.24695181846618652 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 1.4555\n",
      "Epoch 19 Loss 0.721457\n",
      "Time taken for 1 epoch 0.24345612525939941 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 1.4799\n",
      "Epoch 20 Loss 0.728290\n",
      "Time taken for 1 epoch 0.2547619342803955 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for (batch, (img, target)) in enumerate(dataset):\n",
    "        batch_loss, t_loss = train_step(img, target)\n",
    "        total_loss += t_loss\n",
    "    \n",
    "        if batch % 100 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f}'.format(\n",
    "                  epoch + 1, batch, batch_loss.numpy() / int(target.shape[1])))\n",
    "        \n",
    "    loss_plot.append(total_loss / num_steps)\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        ckpt_manager.save()\n",
    "        \n",
    "    print ('Epoch {} Loss {:.6f}'.format(epoch + 1,\n",
    "                                         total_loss/num_steps))\n",
    "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_plot)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(image):\n",
    "    attention_plot = np.zeros((max_length, attention_features_shape))\n",
    "    hidden = decoder.reset_state(batch_size=1)\n",
    "        \n",
    "    img = tf.expand_dims(load_image_only(image), 0) \n",
    "    \n",
    "    features = encoder(img)\n",
    "    \n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['<start>']], 0)\n",
    "    result = []\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        predictions, hidden, attention_weights = decoder(dec_input, features, hidden)\n",
    "        \n",
    "        attention_plot[i] = tf.reshape(attention_weights, (-1, )).numpy()\n",
    "        \n",
    "        predicted_id = tf.random.categorical(predictions, 1)[0][0].numpy()\n",
    "        result.append(tokenizer.index_word[predicted_id])\n",
    "        \n",
    "        if tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, attention_plot\n",
    "        \n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "        \n",
    "    \n",
    "    attention_plot = attention_plot[:len(result), :]\n",
    "    \n",
    "    return result, attention_plot\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(image, result, attention_plot):\n",
    "    temp_image = np.array(Image.open(image))\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    \n",
    "    len_result = len(result)\n",
    "    \n",
    "    for l in range(len_result):\n",
    "        temp_att = np.resize(attention_plot[l], (8, 8))\n",
    "        ax = fig.add_subplot(len_result//2, len_result//2, l+1)\n",
    "        ax.set_title(result[l])\n",
    "        img = ax.imshow(temp_image)\n",
    "        ax.imshow(temp_att, cmap='gray', alpha=0.6, extent=img.get_extent()) \n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Formula: <start> \\frac { \\alpha } { \\beta } <end>\n",
      "Prediction Formula: 1 <end>\n"
     ]
    }
   ],
   "source": [
    "# captions on the validation set\n",
    "rid = np.random.randint(0, len(img_name_val))\n",
    "image = img_name_val[rid]\n",
    "real_caption = ' '.join([tokenizer.index_word[i] for i in cap_val[rid] if i not in [0]])\n",
    "result, attention_plot = evaluate(image)\n",
    "\n",
    "print ('Real Formula:', real_caption)\n",
    "print ('Prediction Formula:', ' '.join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
