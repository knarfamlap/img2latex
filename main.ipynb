{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "import time\n",
    "import pathlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from model.decoder import Decoder\n",
    "from model.encoder import CNN_Encoder\n",
    "from model.attention import BahdanauAttention\n",
    "from model.decoder import embedding_initializer\n",
    "from components.positional import add_timing_signal_nd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test = pathlib.Path(\"data/images_test\")\n",
    "images_train = pathlib.Path(\"data/images_train\")\n",
    "images_val = pathlib.Path(\"data/images_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_formulas = open(\"data/test.formulas.norm.txt\").read().split('\\n')\n",
    "train_formulas = open(\"data/train.formulas.norm.txt\").read().split('\\n')\n",
    "val_formulas = open(\"data/val.fomulas.norm.txt\").read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_formulas)):\n",
    "    test_formulas[i] = \"<start> \" + test_formulas[i] + \" <end>\n",
    "    \n",
    "for i in range(len(train_formlas)):\n",
    "    train_formulas[i] = \"<start> \" + train_formulas[i] + \" <end>\" \n",
    "    \n",
    "for i in range(len(val_formulas)):\n",
    "    val_formulas[i] = \"<start> \" + val_formulas[i] + \" <end>\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(\"data/images_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = list(data_dir.glob(\"*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_paths = []\n",
    "for img in imgs:\n",
    "    imgs_paths.append(os.fspath(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_paths = sorted(set(imgs_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open(\"data/small.formulas.norm.txt\", 'r').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lines)):\n",
    "    lines[i] = \"<start> \" + lines[i] + \" <end>\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 400\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=top_k, oov_token=\"<unk>\", filters='')\n",
    "tokenizer.fit_on_texts(lines)\n",
    "train_seqs = tokenizer.texts_to_sequences(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index['<pad>'] = 0\n",
    "tokenizer.index_word[0] = '<pad>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_vector = tf.keras.preprocessing.sequence.pad_sequences(train_seqs, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = calc_max_length(train_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 80\n",
    "BATCH_SIZE = 2\n",
    "units = 512\n",
    "vocab_size = top_k + 1\n",
    "attention_features_shape = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path, formula):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_png(img)\n",
    "    return img, formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_only(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = img / 255\n",
    "    return img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation sets using an 80-20 split\n",
    "img_name_train, img_name_val, cap_train, cap_val = train_test_split(imgs_paths,\n",
    "                                                                    cap_vector,\n",
    "                                                                    test_size=0.2,\n",
    "                                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((img_name_train, cap_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(1000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = len(img_name_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Encoder Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CNN_Encoder(embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(embedding_dim, 512, vocab_size=top_k+1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(img, target):\n",
    "    loss = 0\n",
    "    img = img / 255\n",
    "    hidden = decoder.reset_state(batch_size=target.shape[0])\n",
    "    \n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * target.shape[0], 1)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        features = encoder(img)\n",
    "        \n",
    "        for i in range(1, target.shape[1]):\n",
    "            predictions, hidden, _ = decoder(dec_input, features, hidden)\n",
    "            \n",
    "            loss += loss_function(target[:, i], predictions)\n",
    "            \n",
    "            dec_input = tf.expand_dims(target[:, i], 1)\n",
    "            \n",
    "        total_loss = (loss / int(target.shape[1]))\n",
    "        \n",
    "        trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "        \n",
    "        gradients = tape.gradient(loss, trainable_variables)\n",
    "        \n",
    "        optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "        \n",
    "        return loss, total_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "ckpt = tf.train.Checkpoint(encoder=encoder, decoder=decoder, optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    start_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])\n",
    "    # restore to latest cehckpoint\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Batch 0 Loss 1.0851\n",
      "Epoch 8 Loss 0.729972\n",
      "Time taken for 1 epoch 0.26508069038391113 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.4762\n",
      "Epoch 9 Loss 0.734448\n",
      "Time taken for 1 epoch 0.24963092803955078 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.4514\n",
      "Epoch 10 Loss 0.733394\n",
      "Time taken for 1 epoch 0.2555880546569824 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.9867\n",
      "Epoch 11 Loss 0.724228\n",
      "Time taken for 1 epoch 0.5438358783721924 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 1.0485\n",
      "Epoch 12 Loss 0.716227\n",
      "Time taken for 1 epoch 0.2555210590362549 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 1.2828\n",
      "Epoch 13 Loss 0.740918\n",
      "Time taken for 1 epoch 0.2597310543060303 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 1.7611\n",
      "Epoch 14 Loss 0.735759\n",
      "Time taken for 1 epoch 0.2511148452758789 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 1.9258\n",
      "Epoch 15 Loss 0.759139\n",
      "Time taken for 1 epoch 0.2526688575744629 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 1.4398\n",
      "Epoch 16 Loss 0.726064\n",
      "Time taken for 1 epoch 0.5296640396118164 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 1.3876\n",
      "Epoch 17 Loss 0.734201\n",
      "Time taken for 1 epoch 0.25580310821533203 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 1.4643\n",
      "Epoch 18 Loss 0.716784\n",
      "Time taken for 1 epoch 0.2648000717163086 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 1.8129\n",
      "Epoch 19 Loss 0.731987\n",
      "Time taken for 1 epoch 0.2696549892425537 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 1.0532\n",
      "Epoch 20 Loss 0.766901\n",
      "Time taken for 1 epoch 0.258342981338501 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 1.4823\n",
      "Epoch 21 Loss 0.741373\n",
      "Time taken for 1 epoch 0.566795825958252 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 1.4663\n",
      "Epoch 22 Loss 0.732260\n",
      "Time taken for 1 epoch 0.2592151165008545 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 1.8164\n",
      "Epoch 23 Loss 0.718215\n",
      "Time taken for 1 epoch 0.27189087867736816 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 1.4561\n",
      "Epoch 24 Loss 0.722017\n",
      "Time taken for 1 epoch 0.2640700340270996 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 1.8830\n",
      "Epoch 25 Loss 0.730732\n",
      "Time taken for 1 epoch 0.26547884941101074 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 1.8352\n",
      "Epoch 26 Loss 0.728900\n",
      "Time taken for 1 epoch 0.5494048595428467 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 1.3655\n",
      "Epoch 27 Loss 0.725189\n",
      "Time taken for 1 epoch 0.26349306106567383 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 1.1277\n",
      "Epoch 28 Loss 0.745082\n",
      "Time taken for 1 epoch 0.2864212989807129 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 1.8770\n",
      "Epoch 29 Loss 0.739861\n",
      "Time taken for 1 epoch 0.28070688247680664 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 1.2372\n",
      "Epoch 30 Loss 0.733828\n",
      "Time taken for 1 epoch 0.26373720169067383 sec\n",
      "\n",
      "Epoch 31 Batch 0 Loss 1.3942\n",
      "Epoch 31 Loss 0.719300\n",
      "Time taken for 1 epoch 0.5589208602905273 sec\n",
      "\n",
      "Epoch 32 Batch 0 Loss 1.4409\n",
      "Epoch 32 Loss 0.718530\n",
      "Time taken for 1 epoch 0.2709629535675049 sec\n",
      "\n",
      "Epoch 33 Batch 0 Loss 1.8363\n",
      "Epoch 33 Loss 0.718759\n",
      "Time taken for 1 epoch 0.27253079414367676 sec\n",
      "\n",
      "Epoch 34 Batch 0 Loss 1.4466\n",
      "Epoch 34 Loss 0.723747\n",
      "Time taken for 1 epoch 0.2794618606567383 sec\n",
      "\n",
      "Epoch 35 Batch 0 Loss 1.3907\n",
      "Epoch 35 Loss 0.720142\n",
      "Time taken for 1 epoch 0.2619960308074951 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 35\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for (batch, (img, target)) in enumerate(dataset):\n",
    "        batch_loss, t_loss = train_step(img, target)\n",
    "        total_loss += t_loss\n",
    "    \n",
    "        if batch % 100 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f}'.format(\n",
    "                  epoch + 1, batch, batch_loss.numpy() / int(target.shape[1])))\n",
    "        \n",
    "    loss_plot.append(total_loss / num_steps)\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        ckpt_manager.save()\n",
    "        \n",
    "    print ('Epoch {} Loss {:.6f}'.format(epoch + 1,\n",
    "                                         total_loss/num_steps))\n",
    "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_plot)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(image):\n",
    "    attention_plot = np.zeros((max_length, attention_features_shape))\n",
    "    hidden = decoder.reset_state(batch_size=1)\n",
    "        \n",
    "    img = tf.expand_dims(load_image_only(image), 0) \n",
    "    \n",
    "    features = encoder(img)\n",
    "    \n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['<start>']], 0)\n",
    "    result = []\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        predictions, hidden, attention_weights = decoder(dec_input, features, hidden)\n",
    "        \n",
    "        attention_plot[i] = tf.reshape(attention_weights, (-1, )).numpy()\n",
    "        \n",
    "        predicted_id = tf.random.categorical(predictions, 1)[0][0].numpy()\n",
    "        result.append(tokenizer.index_word[predicted_id])\n",
    "        \n",
    "        if tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, attention_plot\n",
    "        \n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "        \n",
    "    \n",
    "    attention_plot = attention_plot[:len(result), :]\n",
    "    \n",
    "    return result, attention_plot\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Formula: <start> \\frac { \\alpha } { \\beta } <end>\n",
      "Prediction Formula: \\beta { 1 { <end>\n"
     ]
    }
   ],
   "source": [
    "# captions on the validation set\n",
    "rid = np.random.randint(0, len(img_name_val))\n",
    "image = img_name_val[rid]\n",
    "real_caption = ' '.join([tokenizer.index_word[i] for i in cap_val[rid] if i not in [0]])\n",
    "result, attention_plot = evaluate(image)\n",
    "\n",
    "print ('Real Formula:', real_caption)\n",
    "print ('Prediction Formula:', ' '.join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
